{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTMGenerator.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BovC7TXRtQ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WG2jYOuyF3CQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install chembl_webresource_client"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a85fQKpUL7FY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from chembl_webresource_client.new_client import new_client"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylU4s78kHuPL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "drug_indication = new_client.drug_indication\n",
        "molecules = new_client.molecule\n",
        "lung_cancer_ind = drug_indication.filter(efo_term__icontains=\"LUNG CARCINOMA\")\n",
        "lung_cancer_mols = molecules.filter(molecule_chembl_id__in=[x['molecule_chembl_id'] for x in lung_cancer_ind])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIroTGCpMA6Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lung_cancer_mols"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neckzuKYHzO_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stringCol = \"\"\n",
        "\n",
        "for i in range (0,128):\n",
        "  if lung_cancer_mols[i][\"molecule_structures\"] != None:\n",
        "    if lung_cancer_mols[i][\"molecule_structures\"]['canonical_smiles'] != None:\n",
        "      stringCol = stringCol + \" \" + lung_cancer_mols[i][\"molecule_structures\"]['canonical_smiles']\n",
        "    \n",
        "f = open(\"smiles.txt\", \"w+\")    \n",
        "f.write(stringCol)\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuuKsQ75nsUO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZevPIlnnvDS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#open smile file\n",
        "filename = \"smiles.txt\"\n",
        "raw_text = open(filename, 'r', encoding='utf-8').read()\n",
        "\n",
        "\n",
        "vocab = sorted(list(set(raw_text)))\n",
        "char_to_idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx_to_char = np.array(vocab)\n",
        "\n",
        "mol_as_int = np.array([char_to_idx[c] for c in raw_text])\n",
        "\n",
        "mol_dataset = tf.data.Dataset.from_tensor_slices(mol_as_int)\n",
        "\n",
        "# summarize the loaded data\n",
        "n_chars = len(raw_text)\n",
        "n_vocab = len(idx_to_char)\n",
        "\n",
        "\n",
        "seq_length = 25\n",
        "examples_per_epoch = len(raw_text)//(seq_length+1)\n",
        "sequences = mol_dataset.batch(seq_length+1, drop_remainder=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GTvL09nor4j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create dataset\n",
        "\n",
        "def create_input_target(chunk):\n",
        "    input_text = chunk[:-1]\n",
        "    target_text = chunk[1:]\n",
        "    return input_text, target_text\n",
        "\n",
        "dataset = sequences.map(create_input_target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-hheZf-o0NZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#batching\n",
        "\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "\n",
        "BUFFER_SIZE = 1000\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39gaYGVUpGPD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model\n",
        "\n",
        "def build_model(n_vocab, dmembed, lstm_units, batch_size):\n",
        "  model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(n_vocab, dmembed,\n",
        "                              batch_input_shape=[batch_size, None]),\n",
        "    tf.keras.layers.LSTM(lstm_units,\n",
        "                        return_sequences=True,\n",
        "                        stateful=True,\n",
        "                        recurrent_initializer='glorot_uniform'),\n",
        "    tf.keras.layers.Dense(n_vocab,activation = 'softmax')\n",
        "    \n",
        "  ])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agEJm1_g5_KV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_vocab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YGHLMFFp_KF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create model\n",
        "\n",
        "dmembed = 256\n",
        "\n",
        "lstm_units = 200\n",
        "\n",
        "model = build_model(\n",
        "  n_vocab = n_vocab,\n",
        "  dmembed=dmembed,\n",
        "  lstm_units=lstm_units,\n",
        "  batch_size=BATCH_SIZE)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3j9MPbnqUiz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#loss calc\n",
        "def loss(labels, logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
        "\n",
        "model.compile(optimizer='adam', loss=loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVsSmosOHlyC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCD-5TBb0k9_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "version = model.fit(dataset, epochs=20, callbacks=[checkpoint_callback])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjBLBR1qsXbv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.train.latest_checkpoint(checkpoint_dir)\n",
        "\n",
        "model = build_model(n_vocab, dmembed, lstm_units, batch_size=1)\n",
        "\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "\n",
        "model.build(tf.TensorShape([1, None]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xd1Ufa2Rn3Z3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "def generate_smiles(model, start_string):\n",
        " \n",
        "  mols_generate = 1000\n",
        "\n",
        "\n",
        "  input_data = [char_to_idx[s] for s in start_string]\n",
        "  input_data = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "\n",
        "  smiles_generated = []\n",
        "\n",
        "  \n",
        "  variation = 2.0\n",
        "\n",
        " \n",
        "  model.reset_states()\n",
        "  for i in range(mols_generate):\n",
        "      predictions = model(input_data)\n",
        "\n",
        "      predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "     \n",
        "      predictions = predictions / variation\n",
        "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "\n",
        "     \n",
        "      input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "      smiles_generated.append(idx_to_char[predicted_id])\n",
        "\n",
        "  return (start_string + ''.join(smiles_generated))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVKWkbcTn4QQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed = #CN1CCC[C@H]1c2cccnc\n",
        "gen_smiles = generate_smiles(model, start_string=u\"\")\n",
        "print(gen_smiles)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyoTPhuqujj7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import os\n",
        "import requests\n",
        "import subprocess\n",
        "import shutil\n",
        "from logging import getLogger, StreamHandler, INFO\n",
        "\n",
        "\n",
        "logger = getLogger(__name__)\n",
        "logger.addHandler(StreamHandler())\n",
        "logger.setLevel(INFO)\n",
        "\n",
        "\n",
        "def install(\n",
        "        chunk_size=4096,\n",
        "        file_name=\"Miniconda3-latest-Linux-x86_64.sh\",\n",
        "        url_base=\"https://repo.continuum.io/miniconda/\",\n",
        "        conda_path=os.path.expanduser(os.path.join(\"~\", \"miniconda\")),\n",
        "        rdkit_version=None,\n",
        "        add_python_path=True,\n",
        "        force=False):\n",
        "    \"\"\"install rdkit from miniconda\n",
        "    ```\n",
        "    import rdkit_installer\n",
        "    rdkit_installer.install()\n",
        "    ```\n",
        "    \"\"\"\n",
        "\n",
        "    python_path = os.path.join(\n",
        "        conda_path,\n",
        "        \"lib\",\n",
        "        \"python{0}.{1}\".format(*sys.version_info),\n",
        "        \"site-packages\",\n",
        "    )\n",
        "\n",
        "    if add_python_path and python_path not in sys.path:\n",
        "        logger.info(\"add {} to PYTHONPATH\".format(python_path))\n",
        "        sys.path.append(python_path)\n",
        "\n",
        "    if os.path.isdir(os.path.join(python_path, \"rdkit\")):\n",
        "        logger.info(\"rdkit is already installed\")\n",
        "        if not force:\n",
        "            return\n",
        "\n",
        "        logger.info(\"force re-install\")\n",
        "\n",
        "    url = url_base + file_name\n",
        "    python_version = \"{0}.{1}.{2}\".format(*sys.version_info)\n",
        "\n",
        "    logger.info(\"python version: {}\".format(python_version))\n",
        "\n",
        "    if os.path.isdir(conda_path):\n",
        "        logger.warning(\"remove current miniconda\")\n",
        "        shutil.rmtree(conda_path)\n",
        "    elif os.path.isfile(conda_path):\n",
        "        logger.warning(\"remove {}\".format(conda_path))\n",
        "        os.remove(conda_path)\n",
        "\n",
        "    logger.info('fetching installer from {}'.format(url))\n",
        "    res = requests.get(url, stream=True)\n",
        "    res.raise_for_status()\n",
        "    with open(file_name, 'wb') as f:\n",
        "        for chunk in res.iter_content(chunk_size):\n",
        "            f.write(chunk)\n",
        "    logger.info('done')\n",
        "\n",
        "    logger.info('installing miniconda to {}'.format(conda_path))\n",
        "    subprocess.check_call([\"bash\", file_name, \"-b\", \"-p\", conda_path])\n",
        "    logger.info('done')\n",
        "\n",
        "    logger.info(\"installing rdkit\")\n",
        "    subprocess.check_call([\n",
        "        os.path.join(conda_path, \"bin\", \"conda\"),\n",
        "        \"install\",\n",
        "        \"--yes\",\n",
        "        \"-c\", \"rdkit\",\n",
        "        \"python=={}\".format(python_version),\n",
        "        \"rdkit\" if rdkit_version is None else \"rdkit=={}\".format(rdkit_version)])\n",
        "    logger.info(\"done\")\n",
        "\n",
        "    import rdkit\n",
        "    logger.info(\"rdkit-{} installation finished!\".format(rdkit.__version__))\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    install()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-AOvUxjuktJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from rdkit import Chem\n",
        "\n",
        "genMols = gen_smiles.split()\n",
        "valid_sanitized_mols = []\n",
        "\n",
        "for mol in genMols:\n",
        "  m = Chem.MolFromSmiles(mol,sanitize=False)\n",
        "  if m is None:\n",
        "    print('invalid SMILES')\n",
        "  else:\n",
        "    try:\n",
        "      Chem.SanitizeMol(m)\n",
        "    except:\n",
        "      print('invalid chemistry')\n",
        "  valid_sanitized_mols.append(Chem.MolToSmiles(m))\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjUDHshXJ7xS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "outputfile = open(\"valid_smiles.txt\", \"w+\")\n",
        "f.write(valid_sanitized_mols)\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}