# -*- coding: utf-8 -*-
"""DrugPredictablePropertiesAndActivityDetermination.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17tO5aLKJeO2M6rxH9eCvU8qA4_Bi1qRM
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
from matplotlib import pyplot as plt
from sklearn.ensemble import RandomForestClassifier

# %matplotlib inline

!pip install chembl_webresource_client

import gevent.monkey

gevent.monkey.patch_all()

from chembl_webresource_client.new_client import new_client

import sys
import os
import requests
import subprocess
import shutil
from logging import getLogger, StreamHandler, INFO


logger = getLogger(__name__)
logger.addHandler(StreamHandler())
logger.setLevel(INFO)


def install(
        chunk_size=4096,
        file_name="Miniconda3-latest-Linux-x86_64.sh",
        url_base="https://repo.continuum.io/miniconda/",
        conda_path=os.path.expanduser(os.path.join("~", "miniconda")),
        rdkit_version=None,
        add_python_path=True,
        force=False):
    """install rdkit from miniconda
    ```
    import rdkit_installer
    rdkit_installer.install()
    ```
    """

    python_path = os.path.join(
        conda_path,
        "lib",
        "python{0}.{1}".format(*sys.version_info),
        "site-packages",
    )

    if add_python_path and python_path not in sys.path:
        logger.info("add {} to PYTHONPATH".format(python_path))
        sys.path.append(python_path)

    if os.path.isdir(os.path.join(python_path, "rdkit")):
        logger.info("rdkit is already installed")
        if not force:
            return

        logger.info("force re-install")

    url = url_base + file_name
    python_version = "{0}.{1}.{2}".format(*sys.version_info)

    logger.info("python version: {}".format(python_version))

    if os.path.isdir(conda_path):
        logger.warning("remove current miniconda")
        shutil.rmtree(conda_path)
    elif os.path.isfile(conda_path):
        logger.warning("remove {}".format(conda_path))
        os.remove(conda_path)

    logger.info('fetching installer from {}'.format(url))
    res = requests.get(url, stream=True)
    res.raise_for_status()
    with open(file_name, 'wb') as f:
        for chunk in res.iter_content(chunk_size):
            f.write(chunk)
    logger.info('done')

    logger.info('installing miniconda to {}'.format(conda_path))
    subprocess.check_call(["bash", file_name, "-b", "-p", conda_path])
    logger.info('done')

    logger.info("installing rdkit")
    subprocess.check_call([
        os.path.join(conda_path, "bin", "conda"),
        "install",
        "--yes",
        "-c", "rdkit",
        "python=={}".format(python_version),
        "rdkit" if rdkit_version is None else "rdkit=={}".format(rdkit_version)])
    logger.info("done")

    import rdkit
    logger.info("rdkit-{} installation finished!".format(rdkit.__version__))


if __name__ == "__main__":
    install()

from rdkit import Chem
generatedMol = ["PCPPOO","PPPCPCPO", "Cl.CNCN1C2CCCC2CCC2CCCCC12", "CCCPCPCO", "CNPCP=O", "CC1=C(CC(=O)O)c2cc(Cl)ccc2/C/1=C\c1ccc(cc1)F", "NC(=O)c1ccc(I)c(c1)F", "PPNCCCCPO", "CN1CCCC1c2cccnc2", "CC(C)[C@H](N)C(=O)N1CCC[C@H]1S(O)O"]
inputMols = []
for smiles in generatedMol:
  inputMols.append(Chem.MolFromSmiles(smiles))
generatedMol = inputMols

generatedMol

"""Changes in molecules: 3, 7(deleted)"""

!pip install boost-py

n = 10
from rdkit.Chem import Descriptors
properties = ["Mol_weight","FpDensityMorgan1","MaxAbsPartialCharge","NumHeavyAtoms","NumRotatableBonds","NumAromaticRings", "NumHBA", "NumHBD", "NumLipinskiHBA", "NumLipinskiHBD", "TPSA", "QED_CALC", "LOGP"]
propArr = {}
for factor in properties:
  propArr[factor] = []
value = 0 
for i in range(0,n):
  for factor in properties:
    if factor == "Mol_weight":
      value = Descriptors.ExactMolWt(generatedMol[i])
      propArr[factor].append(value)
    if factor == "FpDensityMorgan1":
      value = Descriptors.FpDensityMorgan1(generatedMol[i])
      propArr[factor].append(value)
    if factor == "MaxAbsPartialCharge":
      value = Descriptors.MaxAbsPartialCharge(generatedMol[i])
      propArr[factor].append(value)
    if factor == "NumHeavyAtoms":
      value = Chem.Lipinski.HeavyAtomCount(generatedMol[i])
      propArr[factor].append(value)
    if factor == "NumRotatableBonds":
      value = Chem.rdMolDescriptors.CalcNumRotatableBonds(generatedMol[i])
      propArr[factor].append(value)
    if factor == "NumAromaticRings":
      value = Chem.rdMolDescriptors.CalcNumAromaticRings(generatedMol[i])
      propArr[factor].append(value)
    if factor == "NumHBA":
      value = Chem.rdMolDescriptors.CalcNumHBA(generatedMol[i])
      propArr[factor].append(value)
    if factor == "NumHBD":
      value = Chem.rdMolDescriptors.CalcNumHBD(generatedMol[i])
      propArr[factor].append(value) 
    if factor == "NumLipinskiHBA":
      value = Chem.rdMolDescriptors.CalcNumLipinskiHBA(generatedMol[i])
      propArr[factor].append(value)
    if factor == "NumLipinskiHBD":
      value = Chem.rdMolDescriptors.CalcNumLipinskiHBD(generatedMol[i])
      propArr[factor].append(value)
    if factor == "TPSA":
      value = Chem.rdMolDescriptors.CalcTPSA(generatedMol[i])
      propArr[factor].append(value) 
    if factor == "QED_CALC":
      value = Chem.QED.weights_mean(generatedMol[i])
      propArr[factor].append(value) 
    if factor == "LOGP":
      value = Chem.Crippen.MolLogP(generatedMol[i])
      propArr[factor].append(value)

for factor in properties:
  print(propArr[factor])

import pandas as pd
index1 = []
for i in range(1,11):
    index1.append(i)

data = pd.DataFrame(data = propArr, index = index1)

#LinpinskiRuleCheck
check = [0]*10

for i in range(0,10):
  if propArr["Mol_weight"][i] > 500:
    check[i] += 1
  if propArr["NumLipinskiHBA"][i] > 10:
    check[i] += 1
  if propArr["NumLipinskiHBD"][i] > 5:
    check[i] += 1
  if propArr["LOGP"][i] > 5:
    check[i] += 1

#GeneralRo5Check

check0 = [0]*10

for i in range(0,10):
  if propArr["Mol_weight"][i] > 500:
    check[i] += 1
  if propArr["NumHBA"][i] > 10:
    check[i] += 1
  if propArr["NumHBD"][i] > 5:
    check[i] += 1
  if propArr["LOGP"][i] > 5:
    check[i] += 1

#ro3 check

check1 = [1]*10

for i in range(0,10):
  if propArr["Mol_weight"][i] > 300:
    check1[i] = 0
    break
  if propArr["NumHBA"][i] > 3:
    check1[i] = 0
    break
  if propArr["NumHBD"][i] > 3:
    check1[i] = 0
    break
  if propArr["LOGP"][i] > 3:
    check1[i] = 0
    break

#adding ro5 and ro3 results

addProps = ["num_lipinski_ro5_violations","num_ro5_violations", "ro3_pass"]

for prop in addProps:
  propArr[prop] = []
value = 0
for i in range(0,n):
  
    value = check[i]
    propArr["num_lipinski_ro5_violations"].append(value)
    value = check0[i]
    propArr["num_ro5_violations"].append(value)
    value = check1[i]
    propArr["ro3_pass"].append(value)

propArr

!pip install chembl_webresource_client

drug_indication = new_client.drug_indication
molecules = new_client.molecule
lung_cancer_ind = drug_indication.filter(efo_term__icontains="LUNG CARCINOMA")
lung_cancer_mols = molecules.filter(molecule_chembl_id__in=[x['molecule_chembl_id'] for x in lung_cancer_ind])

lung_cancer_mols

import pandas as pd



    
arr = lung_cancer_mols[0]['molecule_properties']

arr['active'] = 1
arr_labels = []
for key in arr.keys():
    arr_labels.append(key)
a = []
for i in range(23):
    a.append([])   
    


for q in range(0,23):
    a[q].append(arr[arr_labels[q]])
    
    


index = []
for p in range(1,50):
    count = 1
    list1 = lung_cancer_mols[p]['molecule_properties']
    
    if list1 != None:
      list1['active'] = 1
      if lung_cancer_mols[p]['molecule_properties'] != None and lung_cancer_mols[p]['molecule_properties']['alogp'] != None and lung_cancer_mols[p]['molecule_properties']['full_mwt'] != None:
        if float(lung_cancer_mols[p]['molecule_properties']['full_mwt']) <= float(300):

          for j in range(0,23):
              a[j].append(list1[arr_labels[j]])
          count += 1

l1 = len(a[0])
def makeDict(list1, list2):
    new_Dict = {}
    for i in range(0,23):
        new_Dict[list1[i]] = list2[i]
    return new_Dict
for i in range(1,l1+1):
    index.append(i)

data2 = pd.DataFrame(data = makeDict(arr_labels, a),index = index, copy = True)
data2 = data2[arr_labels]
data2.head()

orig = len(data2)



y = []
for i in range (0,l1):
  y.append([])
predProps = {'acd_logd','acd_logp', 'mw_monoisotopic', 'mw_freebase'}
data2['acd_logd'] = data2['acd_logd'].apply(pd.to_numeric, errors = 'ignore')
data2['acd_logp'] = data2['acd_logp'].apply(pd.to_numeric, errors = 'ignore')
data2['mw_monoisotopic'] = data2['mw_monoisotopic'].apply(pd.to_numeric, errors = 'ignore')
data2['mw_freebase'] = data2['mw_freebase'].apply(pd.to_numeric, errors = 'ignore')
y[0] = data2['active'].values
y[1] = data2['acd_logd'].values
y[2] = data2['acd_logp'].values
y[3] = data2['mw_freebase'].values
y[4] = data2['mw_monoisotopic'].values


    
data2.drop(labels = ['active', 'acd_logd','acd_logp','mw_monoisotopic','mw_freebase','molecular_species', 'acd_most_apka', 'acd_most_bpka', 'full_molformula'], axis = 1, inplace = True)
data2['ro3_pass'].replace(to_replace=['Y'], value = 1,inplace=True)
data2['ro3_pass'].replace(to_replace = ['N'], value = 0, inplace=True)
data2 = data2.apply(pd.to_numeric, errors = 'ignore')
X = data2.iloc[::].values

y[1][4]

X

from statistics import median
import numpy as np
import math
for i in range(0,orig):
    for j in range(0, len(X[i])):
        lst = []
        if math.isnan(X[i][j]):
            for b in range(0,orig):
                if math.isnan(X[b][j]) == False:
                    
                    lst.append(X[b][j])
            X[i][j] = median(lst)
            
for i in range(0,orig):
    for j in range(0, len(X[i])):
        X[i][j] = np.float32(X[i][j])
def median(lst):
    sortedLst = sorted(lst)
    lstLen = len(lst)
    index = (lstLen - 1) // 2

    if (lstLen % 2):
        return sortedLst[index]
    else:
        return (sortedLst[index] + sortedLst[index + 1])/2.0

data3 = {}



for i in range(0,n):
  if i == 0:
    data3['alogp'] = []
    data3['aromatic_rings'] = []
    data3['full_mwt'] = []
    data3['hba'] = []
    data3['hba_lipinski'] = []
    data3['hbd'] = []
    data3['hbd_lipinski'] = []
    data3['heavy_atoms'] = []
    data3['num_lipinski_ro5_violations'] = []
    data3['num_ro5_violations'] = []
    data3['psa'] = []
    data3['qed_weighted'] = [] 
    data3['ro3_pass'] = []
    data3['rtb'] = []
    
  data3['alogp'].append(propArr["LOGP"][i])
  data3['aromatic_rings'].append(propArr["NumAromaticRings"][i])
  data3['full_mwt'].append(propArr["Mol_weight"][i])
  data3['hba'].append(propArr["NumHBA"][i])
  data3['hba_lipinski'].append(propArr["NumLipinskiHBA"][i])
  data3['hbd'].append(propArr["NumHBD"][i])
  data3['hbd_lipinski'].append(propArr["NumLipinskiHBD"][i])
  data3['heavy_atoms'].append(propArr["NumHeavyAtoms"][i])
  data3['num_lipinski_ro5_violations'].append(propArr["num_lipinski_ro5_violations"][i])
  data3['num_ro5_violations'].append(propArr["num_ro5_violations"][i])
  data3['psa'].append(propArr["TPSA"][i])
  data3['qed_weighted'].append(propArr["QED_CALC"][i])
  data3['ro3_pass'].append(propArr['ro3_pass'][i])
  data3['rtb'].append(propArr['NumRotatableBonds'][i])
  
index = []
for q in range(1,11):
  index.append(q)
      
X_test1 = pd.DataFrame(data = data3, index = index) 
X_test1 = X_test1.apply(pd.to_numeric, errors = 'ignore')
X_test1.head()

from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
#Y will be used to collect the calculated properties for each of the 10 compounds
Y = {}
predProps2 = ['acd_logd','acd_logp', 'mw_monoisotopic', 'mw_freebase']
acc = []
for i in range(0,4):
  #division of main dataset
  X_train, X_test, y_train, y_test = train_test_split(X, y[i+1], test_size = 0.3, random_state = 0)
  rf = RandomForestRegressor(n_estimators = 50)
  
  #Fitting the training datasets
  rf.fit(X_train,y_train)
  #Predicted values
  pred = rf.predict(X_test)
  counter = 0 
  for j in range(0, len(pred)):
    #accuracy
    if pred[j] >= 0.9*y_test[j] and pred[j] <= 1.1*(y_test[j]):
      counter += 1
  print(counter/len(pred)*100)
  #properties for new generated compounds
  Y_test1 = rf.predict(X_test1)
  Y[predProps2[i]] = Y_test1

for predProps in predProps2:
  print(Y[predProps])

for i in range(0,n):
  if i == 0:
    data3['mw_freebase'] = []
    data3['mw_monoisotopic'] = []
    
  data3['mw_freebase'].append(Y[predProps2[2]][i])
  data3['mw_monoisotopic'].append(Y[predProps2[3]][i])
  
  
X_test1 = pd.DataFrame(data = data3, index = index)
X_test1 = X_test1.apply(pd.to_numeric, errors = 'ignore')
cols = X_test1.columns.tolist()
temp = cols[14]
cols[14] = cols[15]
cols [15] = temp
print(cols)
cols = cols[0:8] + cols[-2:] + cols [8:(len(cols)-2)]
X_test1 = X_test1[cols]

X_test1.head()

X_test2 = X_test1.iloc[::].values

import pandas as pd



    
arr = lung_cancer_mols[0]['molecule_properties']

arr['active'] = 1
arr_labels = []
for key in arr.keys():
    arr_labels.append(key)
a = []
for i in range(23):
    a.append([])   
    


for q in range(0,23):
    a[q].append(arr[arr_labels[q]])
    
    


index = []
for p in range(1,50):
    count = 1
    list1 = lung_cancer_mols[p]['molecule_properties']
    
    if list1 != None:
      list1['active'] = 1
      if lung_cancer_mols[p]['molecule_properties'] != None and lung_cancer_mols[p]['molecule_properties']['alogp'] != None and lung_cancer_mols[p]['molecule_properties']['full_mwt'] != None:
        if float(lung_cancer_mols[p]['molecule_properties']['full_mwt']) <= float(350):
          for j in range(0,23):
              a[j].append(list1[arr_labels[j]])
          count += 1

l1 = len(a[0])
def makeDict(list1, list2):
    new_Dict = {}
    for i in range(0,23):
        new_Dict[list1[i]] = list2[i]
    return new_Dict
for i in range(1,l1+1):
    index.append(i)
    
dataLung = pd.DataFrame(data = makeDict(arr_labels, a),index = index, copy = True)
dataLung = dataLung[arr_labels]
dataLung.head()

drug_indication = new_client.drug_indication
molecules = new_client.molecule
ovary_cancer_ind = drug_indication.filter(efo_term__icontains="OVARIAN NEOPLASM")
ovary_cancer_mols = molecules.filter(molecule_chembl_id__in=[x['molecule_chembl_id'] for x in ovary_cancer_ind])

drug_indication = new_client.drug_indication
molecules = new_client.molecule
pancreatic_cancer_ind = drug_indication.filter(efo_term__icontains="PANCREATIC NEOPLASM")
pancreatic_cancer_mols = molecules.filter(molecule_chembl_id__in=[x['molecule_chembl_id'] for x in pancreatic_cancer_ind])

#tb
drug_indication = new_client.drug_indication
molecules = new_client.molecule
tb_ind = drug_indication.filter(efo_term__icontains="TUBERCULOSIS")
tb_mols = molecules.filter(molecule_chembl_id__in=[x['molecule_chembl_id'] for x in tb_ind])

pancreatic_cancer_mols[0]['molecule_properties']

import pandas as pd



    
arr = pancreatic_cancer_mols[0]['molecule_properties']


arr['active'] = 0
arr_labels = []
for key in arr.keys():
    arr_labels.append(key)
a = []
for i in range(23):
    a.append([])   
    


for q in range(0,23):
    a[q].append(arr[arr_labels[q]])
    


index2 = []
for p in range(1,30):
    count = 1
    list1 = pancreatic_cancer_mols[p]['molecule_properties']
    if list1 != None:
      list1['active'] = 0
      if pancreatic_cancer_mols[p]['molecule_properties'] != None and pancreatic_cancer_mols[p]['molecule_properties']['alogp'] != None and pancreatic_cancer_mols[p]['molecule_properties']['full_mwt'] != None:
        if float(pancreatic_cancer_mols[p]['molecule_properties']['full_mwt']) <= float(300):
          for j in range(0,23):
              a[j].append(list1[arr_labels[j]])
          count += 1

l2 = len(a[0])
def makeDict(list1, list2):
    new_Dict = {}
    for i in range(0,23):
        new_Dict[list1[i]] = list2[i]
    return new_Dict

for i in range(l1+1, l1 + l2 + 1):
    index2.append(i)
    
dataPan = pd.DataFrame(data = makeDict(arr_labels, a), index = index2)
dataPan = dataPan[arr_labels]
dataPan.head()

import pandas as pd



    
arr = tb_mols[0]['molecule_properties']


arr['active'] = 0
arr_labels = []
for key in arr.keys():
    arr_labels.append(key)
a = []
for i in range(23):
    a.append([])   
    


for q in range(0,23):
    a[q].append(arr[arr_labels[q]])
    


index2 = []
for p in range(1,40):
    count = 1
    list1 = tb_mols[p]['molecule_properties']
    if list1 != None:
      list1['active'] = 0
      if list1 != None and list1['alogp'] != None and list1['full_mwt'] != None:
        if float(list1['full_mwt']) <= float(400):
          for j in range(0,23):
              a[j].append(list1[arr_labels[j]])
          count += 1

l2 = len(a[0])
def makeDict(list1, list2):
    new_Dict = {}
    for i in range(0,23):
        new_Dict[list1[i]] = list2[i]
    return new_Dict

for i in range(l1+1, l1 + l2 + 1):
    index2.append(i)
    
datatb = pd.DataFrame(data = makeDict(arr_labels, a), index = index2)
datatb = datatb[arr_labels]
datatb.head()

import pandas as pd



    
arr = ovary_cancer_mols[0]['molecule_properties']


arr['active'] = 0
arr_labels = []
for key in arr.keys():
    arr_labels.append(key)
a = []
for i in range(23):
    a.append([])   
    


for q in range(0,23):
    a[q].append(arr[arr_labels[q]])
    


index2 = []
for p in range(1,30):
    count = 1
    list1 = ovary_cancer_mols[p]['molecule_properties']
    if list1 != None:
      list1['active'] = 0
      if ovary_cancer_mols[p]['molecule_properties'] != None and ovary_cancer_mols[p]['molecule_properties']['alogp'] != None and ovary_cancer_mols[p]['molecule_properties']['full_mwt'] != None:
        if float(ovary_cancer_mols[p]['molecule_properties']['full_mwt']) <= float(300):
          for j in range(0,23):
              a[j].append(list1[arr_labels[j]])
          count += 1

l3 = len(a[0])
def makeDict(list1, list2):
    new_Dict = {}
    for i in range(0,23):
        new_Dict[list1[i]] = list2[i]
    return new_Dict

for i in range(l1 + l2 +1, l1 + l2 + +l3 + 1):
    index2.append(i)
    
dataOv = pd.DataFrame(data = makeDict(arr_labels, a), index = index2)
dataOv = dataOv[arr_labels]
dataOv.head()



frames = [dataLung, dataOv, dataPan]

dataComb = pd.concat(frames)

dataComb.head()

frames = [dataLung, datatb]

dataComb = pd.concat(frames)

dataComb.head()

orig = len(dataComb)

dataComb.drop(labels = ['full_molformula', "acd_most_apka","acd_most_bpka","molecular_species","acd_logd","acd_logp"],axis = 1,inplace= True)

dataComb['ro3_pass'].replace(to_replace=['Y'], value = 1,inplace=True)
dataComb['ro3_pass'].replace(to_replace = ['N'], value = 0, inplace=True)

dataComb = dataComb.apply(pd.to_numeric, errors = 'ignore')

y = dataComb['active'].values

dataComb.drop(labels = ['active'],axis = 1,inplace= True)
X = dataComb.iloc[::].values

from statistics import median
import numpy as np
import math
for i in range(0,l2 +l1):
    for j in range(0, len(X[i])):
        lst = []
        if math.isnan(X[i][j]):
            for b in range(0,l2+l1):
                if math.isnan(X[b][j]) == False:
                    
                    lst.append(X[b][j])
            X[i][j] = median(lst)
            
for i in range(0,l2+l1):
    for j in range(0, len(X[i])):
        X[i][j] = np.float32(X[i][j])
def median(lst):
    sortedLst = sorted(lst)
    lstLen = len(lst)
    index = (lstLen - 1) // 2

    if (lstLen % 2):
        return sortedLst[index]
    else:
        return (sortedLst[index] + sortedLst[index + 1])/2.0

#model = random forest classifier
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)
from sklearn.ensemble import RandomForestClassifier
rf = RandomForestClassifier(n_estimators = 200)
rf.fit(X_train,y_train)
pred1 = rf.predict(X_test)
#accuracy
from sklearn.metrics import accuracy_score
score = accuracy_score(y_test,pred1)

X_test1.head()

pred2 = rf.predict(X_test1)

pred2

score

#evolutionary algo approach

!pip install deap update_checker tqdm
!pip install tpot

# Commented out IPython magic to ensure Python compatibility.
import numpy as np 
import pandas as pd 
import matplotlib.pyplot as plt 
# %matplotlib inline 
from sklearn import preprocessing 
from sklearn.metrics import mean_squared_error

#a final properties array

props = ["alogp" ,"aromatic_rings", "full_molformula","full_mwt", "hba", "hba_lipinski","hbd", "hbd_lipinski",'heavy_atoms', "mw_freebase","mw_monoistopic","num_lipinski_ro5_violations", "num_ro5_violations","psa","qed_weighted", "ro3_pass","rtb"]

# finally building model using tpot library
from tpot import TPOTRegressor
X_train, X_test, y_train, y_test = train_test_split(X, y,
 train_size=0.75, test_size=0.25)

tpot = TPOTRegressor(generations=12, population_size=50, verbosity=2)
tpot.fit(X_train, y_train)
print(tpot.score(X_test, y_test))

tpot_pred = tpot.predict(X_test)
for i in range(0,len(tpot_pred)):
  tpot_pred[i] = int(round(tpot_pred[i]))
  
tpot_pred

y_test

#my pred

tpot_pred1 = tpot.predict(X_test1)

tpot_pred1

!pip install tpot

# finally building model using tpot library
from tpot import TPOTClassifier
X_train, X_test, y_train, y_test = train_test_split(X, y,
 train_size=0.75, test_size=0.25)

tpot = TPOTClassifier(generations=10, population_size=100, verbosity=2)
tpot.fit(X_train, y_train)
print(tpot.score(X_test, y_test))

"""GradientBoostingClassifier = 0.6"""

tpot_testpred = tpot.predict(X_test)
tpot_testpred

y_test

from sklearn.metrics import accuracy_score

score = accuracy_score(y_test,tpot_testpred)
score

tpot_pred2 = tpot.predict(X_test1)
tpot_pred2