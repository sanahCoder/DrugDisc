{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DrugPredictablePropertiesAndActivityDeterminationNew.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1bl3mViuxpIQ",
        "colab": {}
      },
      "source": [
        "#importing of basic necessary properties\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sKcAxOiS8MBK",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "!pip install chembl_webresource_client"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GAo2lRIy22C6",
        "colab": {}
      },
      "source": [
        "from chembl_webresource_client.new_client import new_client"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kBTOs5v3Je7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#rdkit installation\n",
        "import sys\n",
        "import os\n",
        "import requests\n",
        "import subprocess\n",
        "import shutil\n",
        "from logging import getLogger, StreamHandler, INFO\n",
        "\n",
        "\n",
        "logger = getLogger(__name__)\n",
        "logger.addHandler(StreamHandler())\n",
        "logger.setLevel(INFO)\n",
        "\n",
        "\n",
        "def install(\n",
        "        chunk_size=4096,\n",
        "        file_name=\"Miniconda3-latest-Linux-x86_64.sh\",\n",
        "        url_base=\"https://repo.continuum.io/miniconda/\",\n",
        "        conda_path=os.path.expanduser(os.path.join(\"~\", \"miniconda\")),\n",
        "        rdkit_version=None,\n",
        "        add_python_path=True,\n",
        "        force=False):\n",
        "    \"\"\"install rdkit from miniconda\n",
        "    ```\n",
        "    import rdkit_installer\n",
        "    rdkit_installer.install()\n",
        "    ```\n",
        "    \"\"\"\n",
        "\n",
        "    python_path = os.path.join(\n",
        "        conda_path,\n",
        "        \"lib\",\n",
        "        \"python{0}.{1}\".format(*sys.version_info),\n",
        "        \"site-packages\",\n",
        "    )\n",
        "\n",
        "    if add_python_path and python_path not in sys.path:\n",
        "        logger.info(\"add {} to PYTHONPATH\".format(python_path))\n",
        "        sys.path.append(python_path)\n",
        "\n",
        "    if os.path.isdir(os.path.join(python_path, \"rdkit\")):\n",
        "        logger.info(\"rdkit is already installed\")\n",
        "        if not force:\n",
        "            return\n",
        "\n",
        "        logger.info(\"force re-install\")\n",
        "\n",
        "    url = url_base + file_name\n",
        "    python_version = \"{0}.{1}.{2}\".format(*sys.version_info)\n",
        "\n",
        "    logger.info(\"python version: {}\".format(python_version))\n",
        "\n",
        "    if os.path.isdir(conda_path):\n",
        "        logger.warning(\"remove current miniconda\")\n",
        "        shutil.rmtree(conda_path)\n",
        "    elif os.path.isfile(conda_path):\n",
        "        logger.warning(\"remove {}\".format(conda_path))\n",
        "        os.remove(conda_path)\n",
        "\n",
        "    logger.info('fetching installer from {}'.format(url))\n",
        "    res = requests.get(url, stream=True)\n",
        "    res.raise_for_status()\n",
        "    with open(file_name, 'wb') as f:\n",
        "        for chunk in res.iter_content(chunk_size):\n",
        "            f.write(chunk)\n",
        "    logger.info('done')\n",
        "\n",
        "    logger.info('installing miniconda to {}'.format(conda_path))\n",
        "    subprocess.check_call([\"bash\", file_name, \"-b\", \"-p\", conda_path])\n",
        "    logger.info('done')\n",
        "\n",
        "    logger.info(\"installing rdkit\")\n",
        "    subprocess.check_call([\n",
        "        os.path.join(conda_path, \"bin\", \"conda\"),\n",
        "        \"install\",\n",
        "        \"--yes\",\n",
        "        \"-c\", \"rdkit\",\n",
        "        \"python=={}\".format(python_version),\n",
        "        \"rdkit\" if rdkit_version is None else \"rdkit=={}\".format(rdkit_version)])\n",
        "    logger.info(\"done\")\n",
        "\n",
        "    import rdkit\n",
        "    logger.info(\"rdkit-{} installation finished!\".format(rdkit.__version__))\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    install()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OVlE5Toqx_CQ",
        "colab": {}
      },
      "source": [
        "import rdkit\n",
        "from rdkit import Chem\n",
        "generatedMol = [\"PCPPOO\",\"PPPCPCPO\", \"Cl.CNCN1C2CCCC2CCC2CCCCC12\", \"CCCPCPCO\", \"CNPCP=O\", \"CC1=C(CC(=O)O)c2cc(Cl)ccc2/C/1=C\\c1ccc(cc1)F\", \"NC(=O)c1ccc(I)c(c1)F\", \"PPNCCCCPO\", \"CN1CCCC1c2cccnc2\", \"CC(C)[C@H](N)C(=O)N1CCC[C@H]1S(O)O\"]\n",
        "inputMols = []\n",
        "inputMols = []\n",
        "for smiles in generatedMol:\n",
        "    inputMols.append(Chem.MolFromSmiles(smiles))\n",
        "generatedMol = inputMols\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RNghz1lbyq-N",
        "colab": {}
      },
      "source": [
        "#calculating molecular properties \n",
        "\n",
        "n = 10\n",
        "from rdkit.Chem import Descriptors\n",
        "properties = [\"Mol_weight\",\"FpDensityMorgan1\",\"MaxAbsPartialCharge\",\"NumHeavyAtoms\",\"NumRotatableBonds\",\"NumAromaticRings\", \"NumHBA\", \"NumHBD\", \"NumLipinskiHBA\", \"NumLipinskiHBD\", \"TPSA\", \"QED_CALC\", \"LOGP\"]\n",
        "propArr = {}\n",
        "for factor in properties:\n",
        "    propArr[factor] = []\n",
        "value = 0 \n",
        "for i in range(0,n):\n",
        "    for factor in properties:\n",
        "        if factor == \"Mol_weight\":\n",
        "            value = Descriptors.ExactMolWt(generatedMol[i])\n",
        "            propArr[factor].append(value)\n",
        "        if factor == \"FpDensityMorgan1\":\n",
        "            value = Descriptors.FpDensityMorgan1(generatedMol[i])\n",
        "            propArr[factor].append(value)\n",
        "        if factor == \"MaxAbsPartialCharge\":\n",
        "            value = Descriptors.MaxAbsPartialCharge(generatedMol[i])\n",
        "            propArr[factor].append(value)\n",
        "        if factor == \"NumHeavyAtoms\":\n",
        "            value = Chem.Lipinski.HeavyAtomCount(generatedMol[i])\n",
        "            propArr[factor].append(value)\n",
        "        if factor == \"NumRotatableBonds\":\n",
        "            value = Chem.rdMolDescriptors.CalcNumRotatableBonds(generatedMol[i])\n",
        "            propArr[factor].append(value)\n",
        "        if factor == \"NumAromaticRings\":\n",
        "            value = Chem.rdMolDescriptors.CalcNumAromaticRings(generatedMol[i])\n",
        "            propArr[factor].append(value)\n",
        "        if factor == \"NumHBA\":\n",
        "            value = Chem.rdMolDescriptors.CalcNumHBA(generatedMol[i])\n",
        "            propArr[factor].append(value)\n",
        "        if factor == \"NumHBD\":\n",
        "            value = Chem.rdMolDescriptors.CalcNumHBD(generatedMol[i])\n",
        "            propArr[factor].append(value) \n",
        "        if factor == \"NumLipinskiHBA\":\n",
        "            value = Chem.rdMolDescriptors.CalcNumLipinskiHBA(generatedMol[i])\n",
        "            propArr[factor].append(value)\n",
        "        if factor == \"NumLipinskiHBD\":\n",
        "            value = Chem.rdMolDescriptors.CalcNumLipinskiHBD(generatedMol[i])\n",
        "            propArr[factor].append(value)\n",
        "        if factor == \"TPSA\":\n",
        "            value = Chem.rdMolDescriptors.CalcTPSA(generatedMol[i])\n",
        "            propArr[factor].append(value) \n",
        "        if factor == \"QED_CALC\":\n",
        "            value = Chem.QED.weights_mean(generatedMol[i])\n",
        "            propArr[factor].append(value) \n",
        "        if factor == \"LOGP\":\n",
        "            value = Chem.Crippen.MolLogP(generatedMol[i])\n",
        "            propArr[factor].append(value) \n",
        "      \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2ZO9hu8E8BFV",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "for factor in properties:\n",
        "    print(propArr[factor])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLgM-3n_3zw1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#place collected data in a DataFrame\n",
        "import pandas as pd\n",
        "\n",
        "data = pd.DataFrame(data = propArr, index = range(1,11))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "b3VxG6_yrFhX",
        "colab": {}
      },
      "source": [
        "#LinpinskiRuleCheck\n",
        "check = [0]*10\n",
        "\n",
        "for i in range(0,10):\n",
        "    if propArr[\"Mol_weight\"][i] > 500:\n",
        "        check[i] += 1\n",
        "    if propArr[\"NumLipinskiHBA\"][i] > 10:\n",
        "        check[i] += 1\n",
        "    if propArr[\"NumLipinskiHBD\"][i] > 5:\n",
        "        check[i] += 1\n",
        "    if propArr[\"LOGP\"][i] > 5:\n",
        "        check[i] += 1\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HtrFCr-V9yH0",
        "colab": {}
      },
      "source": [
        "#GeneralRo5Check\n",
        "\n",
        "check0 = [0]*10\n",
        "\n",
        "for i in range(0,10):\n",
        "    if propArr[\"Mol_weight\"][i] > 500:\n",
        "        check0[i] += 1\n",
        "    if propArr[\"NumHBA\"][i] > 10:\n",
        "        check0[i] += 1\n",
        "    if propArr[\"NumHBD\"][i] > 5:\n",
        "        check0[i] += 1\n",
        "    if propArr[\"LOGP\"][i] > 5:\n",
        "        check0[i] += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "n7p6mtJ12iyU",
        "colab": {}
      },
      "source": [
        "#ro3 check\n",
        "\n",
        "check1 = [1]*10\n",
        "\n",
        "for i in range(0,10):\n",
        "    if propArr[\"Mol_weight\"][i] > 300:\n",
        "        check1[i] = 0\n",
        "        break\n",
        "    if propArr[\"NumHBA\"][i] > 3:\n",
        "        check1[i] = 0\n",
        "        break\n",
        "    if propArr[\"NumHBD\"][i] > 3:\n",
        "        check1[i] = 0\n",
        "        break\n",
        "    if propArr[\"LOGP\"][i] > 3:\n",
        "        check1[i] = 0\n",
        "        break\n",
        "    \n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2dEfUCn55tpk",
        "colab": {}
      },
      "source": [
        "#adding ro5 and ro3 results\n",
        "\n",
        "addProps = [\"num_lipinski_ro5_violations\",\"num_ro5_violations\", \"ro3_pass\"]\n",
        "\n",
        "for prop in addProps:\n",
        "    propArr[prop] = []\n",
        "value = 0\n",
        "for i in range(0,n):\n",
        "    value = check[i]\n",
        "    propArr[\"num_lipinski_ro5_violations\"].append(value)\n",
        "    value = check0[i]\n",
        "    propArr[\"num_ro5_violations\"].append(value)\n",
        "    value = check1[i]\n",
        "    propArr[\"ro3_pass\"].append(value)\n",
        "    \n",
        "    \n",
        "    \n",
        "   \n",
        "    \n",
        "\n",
        "                       \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BzrGUNw0BoVd",
        "colab": {}
      },
      "source": [
        "#collecting the lung carcinoma molecules\n",
        "drug_indication = new_client.drug_indication\n",
        "molecules = new_client.molecule\n",
        "lung_cancer_ind = drug_indication.filter(efo_term__icontains=\"LUNG CARCINOMA\")\n",
        "lung_cancer_mols = molecules.filter(molecule_chembl_id__in=[x['molecule_chembl_id'] for x in lung_cancer_ind])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Tjz8VHWQZkrJ",
        "colab": {}
      },
      "source": [
        "n_lung = 100\n",
        "#creating a dataFrame. Note, these molecules are what we consider active (1)\n",
        "import pandas as pd   \n",
        "arr = lung_cancer_mols[0]['molecule_properties']\n",
        "\n",
        "arr['active'] = 1\n",
        "arr_labels = []\n",
        "for key in arr.keys():\n",
        "    arr_labels.append(key)\n",
        "a = []\n",
        "for i in range(23):\n",
        "    a.append([])   \n",
        "for q in range(0,23):\n",
        "    a[q].append(arr[arr_labels[q]])\n",
        "    \n",
        "index = []\n",
        "for p in range(1,n_lung):\n",
        "    count = 1\n",
        "    list1 = lung_cancer_mols[p]['molecule_properties']\n",
        "    #print(list1)\n",
        "    if list1 != None:\n",
        "        list1['active'] = 1\n",
        "        for j in range(0,23):\n",
        "            a[j].append(list1[arr_labels[j]])\n",
        "        count += 1\n",
        "\n",
        "l1 = len(a[0])\n",
        "\n",
        "def makeDict(list1, list2):\n",
        "    new_Dict = {}\n",
        "    for i in range(0,23):\n",
        "        new_Dict[list1[i]] = list2[i]\n",
        "    return new_Dict\n",
        "for i in range(1,l1+1):\n",
        "    index.append(i)\n",
        "\n",
        "data2 = pd.DataFrame(data = makeDict(arr_labels, a),index = index, copy = True)\n",
        "data2 = data2[arr_labels]\n",
        "data2.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVzwCFFZzoYv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#viewing the top 5 entries\n",
        "data2.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fmzmMSuSSDxn",
        "colab": {}
      },
      "source": [
        "#some basic pre-processing\n",
        "orig = len(data2)\n",
        "y = []\n",
        "for i in range (0,l1):\n",
        "    y.append([])\n",
        "predProps = {'acd_logd','acd_logp', 'mw_monoisotopic', 'mw_freebase'}\n",
        "data2['acd_logd'] = data2['acd_logd'].apply(pd.to_numeric, errors = 'ignore')\n",
        "data2['acd_logp'] = data2['acd_logp'].apply(pd.to_numeric, errors = 'ignore')\n",
        "data2['mw_monoisotopic'] = data2['mw_monoisotopic'].apply(pd.to_numeric, errors = 'ignore')\n",
        "data2['mw_freebase'] = data2['mw_freebase'].apply(pd.to_numeric, errors = 'ignore')\n",
        "y[0] = data2['active'].values\n",
        "y[1] = data2['acd_logd'].values\n",
        "y[2] = data2['acd_logp'].values\n",
        "y[3] = data2['mw_freebase'].values\n",
        "y[4] = data2['mw_monoisotopic'].values\n",
        "\n",
        "#too many missing values of 'acd_most_apka', 'acd_most_bpka' and they will not be predicted and used in further analysis\n",
        "\n",
        "data2.drop(labels = ['active', 'acd_logd','acd_logp','mw_monoisotopic','mw_freebase','molecular_species', 'acd_most_apka', 'acd_most_bpka', 'full_molformula'], axis = 1, inplace = True)\n",
        "data2['ro3_pass'].replace(to_replace=['Y'], value = 1,inplace=True)\n",
        "data2['ro3_pass'].replace(to_replace = ['N'], value = 0, inplace=True)\n",
        "data2 = data2.apply(pd.to_numeric, errors = 'ignore')\n",
        "X = data2.iloc[::].values\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpiXkND3zoY0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data2.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NMOImnK3ypWv",
        "colab": {}
      },
      "source": [
        "#placing all rdKit predicted values in a new dictionary with the same order as the chembl dictionary of molecular properties\n",
        "\n",
        "data3 = {}  \n",
        "for i in range(0,n):\n",
        "    if i == 0:\n",
        "        data3['alogp'] = []\n",
        "        data3['aromatic_rings'] = []\n",
        "        data3['full_mwt'] = []\n",
        "        data3['hba'] = []\n",
        "        data3['hba_lipinski'] = []\n",
        "        data3['hbd'] = []\n",
        "        data3['hbd_lipinski'] = []\n",
        "        data3['heavy_atoms'] = []\n",
        "        data3['num_lipinski_ro5_violations'] = []\n",
        "        data3['num_ro5_violations'] = []\n",
        "        data3['psa'] = []\n",
        "        data3['qed_weighted'] = [] \n",
        "        data3['ro3_pass'] = []\n",
        "        data3['rtb'] = []\n",
        "\n",
        "    data3['alogp'].append(propArr[\"LOGP\"][i])\n",
        "    data3['aromatic_rings'].append(propArr[\"NumAromaticRings\"][i])\n",
        "    data3['full_mwt'].append(propArr[\"Mol_weight\"][i])\n",
        "    data3['hba'].append(propArr[\"NumHBA\"][i])\n",
        "    data3['hba_lipinski'].append(propArr[\"NumLipinskiHBA\"][i])\n",
        "    data3['hbd'].append(propArr[\"NumHBD\"][i])\n",
        "    data3['hbd_lipinski'].append(propArr[\"NumLipinskiHBD\"][i])\n",
        "    data3['heavy_atoms'].append(propArr[\"NumHeavyAtoms\"][i])\n",
        "    data3['num_lipinski_ro5_violations'].append(propArr[\"num_lipinski_ro5_violations\"][i])\n",
        "    data3['num_ro5_violations'].append(propArr[\"num_ro5_violations\"][i])\n",
        "    data3['psa'].append(propArr[\"TPSA\"][i])\n",
        "    data3['qed_weighted'].append(propArr[\"QED_CALC\"][i])\n",
        "    data3['ro3_pass'].append(propArr['ro3_pass'][i])\n",
        "    data3['rtb'].append(propArr['NumRotatableBonds'][i])\n",
        "\n",
        "index = [] \n",
        "for q in range(1,11):\n",
        "    index.append(q)\n",
        "      \n",
        "X_test1 = pd.DataFrame(data = data3, index = index) \n",
        "X_test1 = X_test1.apply(pd.to_numeric, errors = 'ignore')\n",
        "X_test1.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QSkDaajoe7g8",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "#Y will be used to collect the calculated properties for each of the 10 compounds\n",
        "Y = {}\n",
        "predProps2 = ['acd_logd','acd_logp', 'mw_monoisotopic', 'mw_freebase']\n",
        "acc = []\n",
        "for i in range(0,4):\n",
        "    #division of main dataset\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y[i+1], test_size = 0.3, random_state = 0)\n",
        "    rf = RandomForestRegressor(n_estimators = 50)\n",
        "\n",
        "    #Fitting the training datasets\n",
        "    rf.fit(X_train,y_train)\n",
        "    #Predicted values\n",
        "    pred = rf.predict(X_test)\n",
        "    #properties for new generated compounds\n",
        "    Y_test1 = rf.predict(X_test1)\n",
        "    Y[predProps2[i]] = Y_test1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GaWkQfV-Nq6j",
        "colab": {}
      },
      "source": [
        "for predProps in predProps2:\n",
        "    print(Y[predProps])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PJzMb7eh0IFJ",
        "colab": {}
      },
      "source": [
        "#adding 'mw_monoisotopic'and 'mw_freebase' into the dictionary of molecular properties (these two properties were predicted with higher accuracies than the other two 'acd_logd','acd_logp')\n",
        "\n",
        "for i in range(0,n):\n",
        "    if i == 0:\n",
        "        data3['mw_monoisotopic'] = []\n",
        "        data3['mw_freebase'] = []\n",
        "    data3['mw_freebase'].append(Y[predProps2[2]][i])\n",
        "    data3['mw_monoisotopic'].append(Y[predProps2[3]][i])\n",
        "  \n",
        "  \n",
        "X_test1 = pd.DataFrame(data = data3, index = index)\n",
        "X_test1 = X_test1.apply(pd.to_numeric, errors = 'ignore')\n",
        "cols = X_test1.columns.tolist()\n",
        "cols = cols[0:8] + cols[-2:] + cols [8:(len(cols)-2)]\n",
        "X_test1 = X_test1[cols]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eOCOezVuWZj2",
        "colab": {}
      },
      "source": [
        "X_test1.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKAamFRy8KND",
        "colab_type": "text"
      },
      "source": [
        "#### Activity Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kt6TcNFjfPxl",
        "colab": {}
      },
      "source": [
        "#Prediction of activity of generated molecules\n",
        "\n",
        "import pandas as pd\n",
        "arr = lung_cancer_mols[0]['molecule_properties']\n",
        "\n",
        "arr['active'] = 1\n",
        "arr_labels = []\n",
        "for key in arr.keys():\n",
        "    arr_labels.append(key)\n",
        "a = []\n",
        "for i in range(23):\n",
        "    a.append([])   \n",
        "for q in range(0,23):\n",
        "    a[q].append(arr[arr_labels[q]])\n",
        "    \n",
        "index = []\n",
        "for p in range(1,n_lung):\n",
        "    count = 1\n",
        "    list1 = lung_cancer_mols[p]['molecule_properties']\n",
        "    #print(list1)\n",
        "    if list1 != None:\n",
        "        list1['active'] = 1\n",
        "        for j in range(0,23):\n",
        "            a[j].append(list1[arr_labels[j]])\n",
        "            count += 1\n",
        "\n",
        "l1 = len(a[0])\n",
        "def makeDict(list1, list2):\n",
        "    new_Dict = {}\n",
        "    for i in range(0,23):\n",
        "        new_Dict[list1[i]] = list2[i]\n",
        "    return new_Dict\n",
        "for i in range(1,l1+1):\n",
        "    index.append(i)\n",
        "    \n",
        "dataLung = pd.DataFrame(data = makeDict(arr_labels, a),index = index, copy = True)\n",
        "dataLung = dataLung[arr_labels]\n",
        "#dataLung.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_H6Yn2lzoZO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#tb_molecules: Activity = 0 \n",
        "drug_indication = new_client.drug_indication\n",
        "molecules = new_client.molecule\n",
        "tb_ind = drug_indication.filter(efo_term__icontains=\"TUBERCULOSIS\")\n",
        "tb_mols = molecules.filter(molecule_chembl_id__in=[x['molecule_chembl_id'] for x in tb_ind])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vcU6_dIEflxL",
        "colab": {}
      },
      "source": [
        "n_tb = 100\n",
        "import pandas as pd\n",
        "arr = tb_mols[0]['molecule_properties']\n",
        "arr['active'] = 0\n",
        "arr_labels = []\n",
        "for key in arr.keys():\n",
        "    arr_labels.append(key)\n",
        "a = []\n",
        "for i in range(23):\n",
        "    a.append([])   \n",
        "for q in range(0,23):\n",
        "    a[q].append(arr[arr_labels[q]])\n",
        "    \n",
        "index2 = []\n",
        "for p in range(1,40):\n",
        "    count = 1\n",
        "    list1 = tb_mols[p]['molecule_properties']\n",
        "    if list1 != None:\n",
        "        list1['active'] = 0\n",
        "    \n",
        "        for j in range(0, n_tb):\n",
        "            a[j].append(list1[arr_labels[j]])\n",
        "            count += 1\n",
        "\n",
        "l2 = len(a[0])\n",
        "def makeDict(list1, list2):\n",
        "    new_Dict = {}\n",
        "    for i in range(0,23):\n",
        "        new_Dict[list1[i]] = list2[i]\n",
        "    return new_Dict\n",
        "\n",
        "for i in range(l1+1, l1+l2+1):\n",
        "    index2.append(i)\n",
        "    \n",
        "datatb = pd.DataFrame(data = makeDict(arr_labels, a), index = index2)\n",
        "datatb = datatb[arr_labels]\n",
        "datatb.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "xBMvSYg1zoZk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datatb.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aUqC4axod5zw",
        "colab": {}
      },
      "source": [
        "frames = [dataLung, datatb]\n",
        "\n",
        "dataComb = pd.concat(frames)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkVg42OczoZo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataComb.to_csv(\"dataComb\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbAcfky7zoZr",
        "colab_type": "text"
      },
      "source": [
        "### Analysis and  preprocessing the data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hsGkZPXzoZs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#full_molformula will be unique for each molecule\n",
        "dataComb.drop(labels = ['full_molformula'],axis = 1,inplace= True) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDugF5ftzoZ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# categorical features treatment \n",
        "!pip install category-encoders\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzof-qtyzoZ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import category_encoders as ce\n",
        "\n",
        "ce_OHE = ce.OneHotEncoder(cols = ['molecular_species',\"ro3_pass\"])\n",
        "dataComb = ce_OHE.fit_transform(dataComb)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngneHSKmzoZ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataComb.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "_Nnkv2-SzoaE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataComb.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrFVmwS1zoaG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#converting the obejct types features to numeric\n",
        "cat_labels = dataComb.select_dtypes(include = [\"object\"]).columns\n",
        "dataComb[cat_labels] = dataComb[cat_labels].apply(pd.to_numeric)\n",
        "\n",
        "dataComb.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnNo-A9JzoaJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataComb.isnull().sum()\n",
        "dataComb.head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRo8s7l6zoaL",
        "colab_type": "text"
      },
      "source": [
        "#### Analysing data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ss7bWK5izoaT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#these two properties were not predicted before for the generated compounds\n",
        "df1 = dataComb.drop(labels=[\"acd_most_apka\",\"acd_most_bpka\", \"acd_logp\", \"acd_logd\"],axis = 1)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oFDkNvizoac",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# SPLITING DATA INTO predictors/response variables \n",
        "\n",
        "X = df1.iloc[:,:-1]\n",
        "y = df1.iloc[:,-1]\n",
        "\n",
        "X.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "N7h-T3LFzoaf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#treating missing values \n",
        "from scipy.stats import mode\n",
        "X= X.fillna({\"psa\":X.psa.median(),\n",
        "             \"num_ro5_violations\":X.num_ro5_violations.mode(),\n",
        "             \"mw_monoisotopic\":X.mw_monoisotopic.mean(),\n",
        "             \"mw_freebase\": X.mw_freebase.mean(),\n",
        "             \"heavy_atoms\": X.heavy_atoms.median(),\n",
        "             \"hbd_lipinski\": X.heavy_atoms.median(),\n",
        "             \"hba_lipinski\": X.heavy_atoms.median(),\n",
        "             \"alogp\":X.alogp.mean(),\n",
        "             \"aromatic_rings\":X.aromatic_rings.median(),\n",
        "             \"hba\":X.hba.median(),\n",
        "             \"hbd\":X.hbd.median(),\n",
        "             \"num_lipinski_ro5_violations\": 0.0,\n",
        "             \"qed_weighted\":X.qed_weighted.mean(),\n",
        "             \"rtb\":X.rtb.median()})\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EtQownPzoai",
        "colab_type": "text"
      },
      "source": [
        "### Skewness in data distribution of original dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ews-EfJzoai",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_skew = X.skew()\n",
        "skewness = X_skew[abs(X_skew) > 0.5] \n",
        "skewed_features = skewness.index\n",
        "print(skewed_features)\n",
        "skewness"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEl2bm2wDcaY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0qJuP-izoak",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#skewness treatment taking/trasnforming\n",
        "xsk=X.iloc[:,:]\n",
        "xsk[skewed_features] = np.log1p(xsk[skewed_features])\n",
        "#xsk =\n",
        "xsk.skew()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQqBkBcczoap",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#removing highly skewed variables\n",
        "X_skew_removed = xsk.drop([\"num_lipinski_ro5_violations\", \"num_ro5_violations\",\"molecular_species_1\",\"molecular_species_2\",\n",
        "       \"molecular_species_3\",\"molecular_species_4\",\"molecular_species_5\",\"ro3_pass_1\",\"ro3_pass_2\"], axis = 1 )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mligPKJazoat",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_skew_removed.skew()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bv0uApRJzoav",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import seaborn as sns \n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRYC5R5izoay",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "# visualising the distribution\n",
        "sns.pairplot(X_skew_removed)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kWHxFnvEXvQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_skew_removed.head(40)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4vkEhFBFmhc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " X_skew_removed[\"alogp\"] = X_skew_removed[\"alogp\"].interpolate()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCKK2jE9F675",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_skew_removed.head(40)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3q2SFMp6kmC8",
        "colab_type": "text"
      },
      "source": [
        "#### Skewness in data distribution of generated molecules data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLpBOXC0ZtcO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "skewness = X_skew[abs(X_skew) > 0.5] \n",
        "skewed_features = skewness.index\n",
        "X_skew1 = X_test1.skew()\n",
        "xsk1 = X_test1.iloc[:,:]\n",
        "xsk1[skewed_features] = np.log1p(xsk1[skewed_features])\n",
        "#xsk =\n",
        "xsk1.skew()\n",
        "\n",
        "X_test1 = xsk1.drop([\"num_lipinski_ro5_violations\", \"num_ro5_violations\", \"ro3_pass\"],axis =1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqojZ0vazoa1",
        "colab_type": "text"
      },
      "source": [
        "#### logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "OBXcsGUUzoa2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "#Logistic regression \n",
        "def logistic_reg(a,b):\n",
        "    \"\"\"LogisticRegression classifier with optimised parameters ,\n",
        "    stratifiedKfold is used for imbalance data  \"\"\" \n",
        "    import seaborn as sns \n",
        "    import matplotlib.pyplot as plt\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    #from sklearn.model_selection import KFold\n",
        "    from sklearn.model_selection import StratifiedKFold \n",
        "    from sklearn.model_selection import cross_val_score\n",
        "    from sklearn.linear_model import LogisticRegression\n",
        "    from sklearn import metrics\n",
        "    \n",
        "    X_train, X_test, y_train, y_test = train_test_split(a, b, test_size=0.25, random_state=42)\n",
        "    model_lr = LogisticRegression(penalty='l1',n_jobs=-1)\n",
        "    model_lr.fit(X_train,y_train)\n",
        "    y_pred=model_lr.predict(X_test)\n",
        "    \n",
        "    str_kfold = StratifiedKFold(n_splits=10, random_state=42)\n",
        "    accuracy = cross_val_score(model_lr, a, b, cv=str_kfold,scoring='accuracy')\n",
        "    print('cross_ validation Accuracy : ',np.mean(accuracy))\n",
        "    \n",
        "    confusion_matrix = pd.crosstab(y_test, y_pred, rownames=['Actual'], colnames=['Predicted'])\n",
        "    #print(confusion_matrix)\n",
        "    sns.heatmap(confusion_matrix, annot=True)\n",
        "    plt.show()\n",
        "    return model_lr \n",
        "    \n",
        "\n",
        "logistic_reg(X_skew_removed,y)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7OhCMpszoa6",
        "colab_type": "text"
      },
      "source": [
        "#### k-NN classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "jZ5geChqzoa6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "def knn_classifier(a,b):\n",
        "    \"\"\"K-nearest neighbour classifier with optimised parameters.\n",
        "    \"\"\"\n",
        "    #Spliting data into train/validation sets \n",
        "    from sklearn.model_selection import train_test_split\n",
        "    #from sklearn.model_selection import KFold\n",
        "    from sklearn.model_selection import StratifiedKFold\n",
        "    from sklearn.model_selection import cross_val_score\n",
        "    from sklearn.model_selection import GridSearchCV\n",
        "    from sklearn.neighbors import KNeighborsClassifier\n",
        "    from sklearn import metrics\n",
        "    \n",
        "    X_train, X_test, y_train, y_test = train_test_split(a, b, test_size=0.25, random_state=42)\n",
        "    model = KNeighborsClassifier()\n",
        "    model.fit(X_train, y_train)\n",
        "    #y_pred=model.predict(X_test)\n",
        "    \n",
        "    #validating the model\n",
        "    str_kfold = StratifiedKFold(n_splits=10, random_state=42) #giving better result\n",
        "    \n",
        "    param_grid = dict(n_neighbors=[3,4,5,6,7,8,9])\n",
        "    grid_model = GridSearchCV(model, param_grid, scoring='accuracy', n_jobs=-1, cv=str_kfold)\n",
        "    grid_result = grid_model.fit(a, b)\n",
        "    y_pred = grid_model.predict(X_test)\n",
        "    \n",
        "    #print(a.columns)\n",
        "    \n",
        "    print(f\"best parameters:{grid_result.best_params_ } , best accuracy:{grid_result.best_score_}\")\n",
        "    \n",
        "    accuracy = cross_val_score(grid_model, a, b, cv=str_kfold,scoring='accuracy')\n",
        "    print('cross_ validation Accuracy : ',np.mean(accuracy))\n",
        "    return grid_model\n",
        "    \n",
        "\n",
        "knn_classifier(X_skew_removed,y)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmOfDqPfzoa9",
        "colab_type": "text"
      },
      "source": [
        "#### Random-Forest classifier "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vENqH0OWzoa-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#random forest\n",
        "def rf_classifier(a,b):\n",
        "    \"\"\"RandomForest classifier with optimised parameters.\n",
        "    \"\"\"\n",
        "    #Spliting data into train/validation sets \n",
        "    from sklearn.model_selection import train_test_split\n",
        "    #from sklearn.model_selection import KFold\n",
        "    from sklearn.model_selection import StratifiedKFold\n",
        "    from sklearn.model_selection import cross_val_score\n",
        "    from sklearn.model_selection import GridSearchCV\n",
        "    from sklearn.ensemble import RandomForestClassifier\n",
        "    from sklearn import metrics\n",
        "    X_train, X_test, y_train, y_test = train_test_split(a, b, test_size=0.3, random_state=42)\n",
        "    \n",
        "    rf = RandomForestClassifier()\n",
        "    str_kfold = StratifiedKFold(n_splits=10, random_state=42)\n",
        "    param_grid = dict(n_estimators=np.arange(10,60,5),criterion=[\"gini\",\"entropy\"])\n",
        "    \n",
        "    grid_model = GridSearchCV(rf, param_grid, scoring='accuracy', n_jobs=-1, cv=str_kfold)\n",
        "    grid_result = grid_model.fit(X_train, y_train)\n",
        "    \n",
        "    print(grid_result.best_params_ , grid_result.best_score_)\n",
        "    \n",
        "    accuracy = cross_val_score(grid_model, X_test, y_test, cv=str_kfold,scoring='accuracy')\n",
        "    print('cross_ validation Accuracy : ',np.mean(accuracy))\n",
        "    return grid_model\n",
        "\n",
        "classifier = rf_classifier(X_skew_removed,y)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYMS7yf-zobE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install xgboost"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agZr6NANzobG",
        "colab_type": "text"
      },
      "source": [
        "#### XGBoost classifier \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "lpBG_RA9zobH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def xgb_classifier(a,b):\n",
        "    \"\"\"XGBoost classifier with optimised parameters.\n",
        "    \"\"\"\n",
        "    #Spliting data into train/validation sets \n",
        "    from sklearn.model_selection import train_test_split\n",
        "    #from sklearn.model_selection import KFold\n",
        "    from sklearn.model_selection import StratifiedKFold\n",
        "    from sklearn.model_selection import cross_val_score\n",
        "    from sklearn.model_selection import GridSearchCV\n",
        "    from xgboost import XGBClassifier\n",
        "    from sklearn import metrics\n",
        "    X_train, X_test, y_train, y_test = train_test_split(a, b, test_size=0.25, random_state=42)\n",
        "    \n",
        "    xgb = XGBClassifier()\n",
        "    #xgb.fit(X_train, y_train)\n",
        "    param_grid = dict(learning_rate=[0.01,0.05,0.10,0.2,0.3], \n",
        "                      n_estimators=np.arange(1,50,10), \n",
        "                      reg_alpha = np.arange(0.1,1,0.2),\n",
        "                      max_depth=[2,4,6,8], \n",
        "                      gamma=[0,1,5])\n",
        "    \n",
        "    str_kfold = StratifiedKFold(n_splits=10, random_state=42)\n",
        "    \n",
        "    grid_model = GridSearchCV(xgb, param_grid, scoring='accuracy', n_jobs=-1, cv=str_kfold)\n",
        "    grid_result = grid_model.fit(X_train,  y_train)\n",
        "    \n",
        "    print(grid_result.best_params_ , grid_result.best_score_)\n",
        "    best_parm = grid_result.best_params_ \n",
        "    model = XGBClassifier(learning_rate=best_parm[\"learning_rate\"],\n",
        "                      objective=\"binary:logistic\", \n",
        "                      n_estimators=best_parm[\"n_estimators\"], \n",
        "                      reg_alpha = best_parm[\"reg_alpha\"],\n",
        "                      max_depth=best_parm[\"max_depth\"], \n",
        "                      gamma=best_parm[\"gamma\"])\n",
        "    model.fit(X_train, y_train)\n",
        "    accuracy = cross_val_score(model,  X_test, y_test, cv=str_kfold,scoring='accuracy')\n",
        "    print('cross_ validation Accuracy : ',np.mean(accuracy))\n",
        "    return model\n",
        "\n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBYnZdzPzobL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_xgb = xgb_classifier(X_skew_removed,y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZiR9dbwzobN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_xgb.feature_importances_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLhNjgL6zobP",
        "colab_type": "text"
      },
      "source": [
        "#### Predicting the generated molecules\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRG7_OjKzobP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Random forest and Xgboost models gave the same average accuracy; used Random Forest for this example\n",
        "pred = classifier.predict(X_test1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRXRsxBm-SIa",
        "colab_type": "text"
      },
      "source": [
        "####Genetic Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtzSnjNk-XVB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#download the tpot classifier\n",
        "!pip install tpot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fd26XUkR-ZGS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tpot import TPOTClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4iOKhdeJ_ZE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def geneticModel(a,b):\n",
        "  X_train, X_test, y_train, y_test = train_test_split(a, b,\n",
        "  train_size=0.75, test_size=0.25)\n",
        "\n",
        "  tpot = TPOTClassifier(generations=12, population_size=100, verbosity=2)\n",
        "  tpot.fit(X_train,y_train)\n",
        "  print(classifier.score(X_test, y_test))\n",
        "  return tpot\n",
        "\n",
        "classifier = geneticModel(X_skew_removed,y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQP0OD_5Mm6o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = classifier.predict(Xtest1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtgWlmaBNIST",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}